{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "zU3LFEsYURaw"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "@author: Praveen Dominic\n",
        "\"\"\"\n",
        "from keras.datasets import mnist\n",
        "from keras.layers import Input, Dense, Reshape, Flatten\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers import LeakyReLU\n",
        "from keras.models import Sequential, Model\n",
        "from keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "img_rows = 28\n",
        "img_cols = 28\n",
        "channels = 1\n",
        "img_shape = (img_rows, img_cols, channels)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_generator():\n",
        "\n",
        "    noise_shape = (100,) #1D array of size 100 (latent vector / noise)\n",
        "\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Dense(256, input_shape=noise_shape))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "    model.add(Dense(512))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "    model.add(Dense(1024))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "    \n",
        "    model.add(Dense(np.prod(img_shape), activation='tanh'))\n",
        "    model.add(Reshape(img_shape))\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    noise = Input(shape=noise_shape)\n",
        "    img = model(noise)    #Generated image\n",
        "\n",
        "    return Model(noise, img)\n"
      ],
      "metadata": {
        "id": "TZB8YGoHUhg3"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_discriminator():\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Flatten(input_shape=img_shape))\n",
        "    model.add(Dense(512))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Dense(256))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    model.summary()\n",
        "\n",
        "    img = Input(shape=img_shape)\n",
        "    validity = model(img)\n",
        "\n",
        "    return Model(img, validity)"
      ],
      "metadata": {
        "id": "DbKweY1BUs7a"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(epochs, batch_size=128, save_interval=50):\n",
        "\n",
        "    # Load the dataset\n",
        "    (X_train, _), (_, _) = mnist.load_data()\n",
        "\n",
        "    # Convert to float and Rescale -1 to 1 (Can also do 0 to 1)\n",
        "    X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
        "\n",
        "    X_train = np.expand_dims(X_train, axis=3) \n",
        "\n",
        "    half_batch = int(batch_size / 2)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        #  Train Discriminator\n",
        "\n",
        "        # Select a random half batch of real images\n",
        "        idx = np.random.randint(0, X_train.shape[0], half_batch)\n",
        "        imgs = X_train[idx]\n",
        "\n",
        " \n",
        "        noise = np.random.normal(0, 1, (half_batch, 100))\n",
        "\n",
        "        # Generate a half batch of fake images\n",
        "        gen_imgs = generator.predict(noise)\n",
        "\n",
        "        # Train the discriminator on real and fake images, separately\n",
        "        d_loss_real = discriminator.train_on_batch(imgs, np.ones((half_batch, 1)))\n",
        "        d_loss_fake = discriminator.train_on_batch(gen_imgs, np.zeros((half_batch, 1)))\n",
        "    #take average loss from real and fake images. \n",
        "        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake) \n",
        "\n",
        "        noise = np.random.normal(0, 1, (batch_size, 100)) \n",
        "\n",
        "        valid_y = np.array([1] * batch_size) #Creates an array of all ones of size=batch size\n",
        "\n",
        "        g_loss = combined.train_on_batch(noise, valid_y)\n",
        "\n",
        "        \n",
        "        print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n",
        "\n",
        "        # If at save interval => save generated image samples\n",
        "        if epoch % save_interval == 0:\n",
        "            save_imgs(epoch)"
      ],
      "metadata": {
        "id": "-0OSGMGeUvcq"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_imgs(epoch):\n",
        "    r, c = 5, 5\n",
        "    noise = np.random.normal(0, 1, (r * c, 100))\n",
        "    gen_imgs = generator.predict(noise)\n",
        "\n",
        "    # Rescale images 0 - 1\n",
        "    gen_imgs = 0.5 * gen_imgs + 0.5\n",
        "\n",
        "    fig, axs = plt.subplots(r, c)\n",
        "    cnt = 0\n",
        "    for i in range(r):\n",
        "        for j in range(c):\n",
        "            axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')\n",
        "            axs[i,j].axis('off')\n",
        "            cnt += 1\n",
        "    fig.savefig(\"/content/drive/MyDrive/DL/CNN/GAN/images/mnist_%d.png\" % epoch)\n",
        "    plt.close()"
      ],
      "metadata": {
        "id": "inb6Qb5dU9Em"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = Adam(0.0002, 0.5)  #Learning rate and momentum.\n",
        "\n",
        "discriminator = build_discriminator()\n",
        "discriminator.compile(loss='binary_crossentropy',\n",
        "    optimizer=optimizer,\n",
        "    metrics=['accuracy'])\n",
        "\n",
        "generator = build_generator()\n",
        "generator.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
        "\n",
        "#In a GAN the Generator network takes noise z as an input to produce its images.  \n",
        "z = Input(shape=(100,))   #Our random input to the generator\n",
        "img = generator(z)\n",
        "\n",
        "#While generator training we do not want discriminator weights to be adjusted. \n",
        "#This Doesn't affect the above descriminator training.     \n",
        "discriminator.trainable = False  \n",
        "\n",
        "valid = discriminator(img)  #Validity check on the generated image\n",
        "\n",
        "combined = Model(z, valid)\n",
        "combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
        "\n",
        "\n",
        "train(epochs=100, batch_size=32, save_interval=10)\n",
        "\n",
        "generator.save('generator_model.h5') "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GW5zz-FIU_ce",
        "outputId": "71d04973-ba3f-442f-cfb8-256b1c3b46ec"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_2 (Flatten)         (None, 784)               0         \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 512)               401920    \n",
            "                                                                 \n",
            " leaky_re_lu_10 (LeakyReLU)  (None, 512)               0         \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 256)               131328    \n",
            "                                                                 \n",
            " leaky_re_lu_11 (LeakyReLU)  (None, 256)               0         \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 533,505\n",
            "Trainable params: 533,505\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_17 (Dense)            (None, 256)               25856     \n",
            "                                                                 \n",
            " leaky_re_lu_12 (LeakyReLU)  (None, 256)               0         \n",
            "                                                                 \n",
            " batch_normalization_6 (Batc  (None, 256)              1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 512)               131584    \n",
            "                                                                 \n",
            " leaky_re_lu_13 (LeakyReLU)  (None, 512)               0         \n",
            "                                                                 \n",
            " batch_normalization_7 (Batc  (None, 512)              2048      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 1024)              525312    \n",
            "                                                                 \n",
            " leaky_re_lu_14 (LeakyReLU)  (None, 1024)              0         \n",
            "                                                                 \n",
            " batch_normalization_8 (Batc  (None, 1024)             4096      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 784)               803600    \n",
            "                                                                 \n",
            " reshape_2 (Reshape)         (None, 28, 28, 1)         0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,493,520\n",
            "Trainable params: 1,489,936\n",
            "Non-trainable params: 3,584\n",
            "_________________________________________________________________\n",
            "1/1 [==============================] - 0s 118ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 7 calls to <function Model.make_train_function.<locals>.train_function at 0x7fcefeda9440> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 9 calls to <function Model.make_train_function.<locals>.train_function at 0x7fcefecc68c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 [D loss: 1.013795, acc.: 18.75%] [G loss: 0.662124]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1 [D loss: 0.426440, acc.: 81.25%] [G loss: 0.678412]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "2 [D loss: 0.356052, acc.: 87.50%] [G loss: 0.689094]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3 [D loss: 0.338994, acc.: 84.38%] [G loss: 0.819366]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "4 [D loss: 0.294039, acc.: 96.88%] [G loss: 0.830182]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "5 [D loss: 0.296468, acc.: 93.75%] [G loss: 0.922580]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "6 [D loss: 0.257082, acc.: 100.00%] [G loss: 1.074389]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "7 [D loss: 0.212408, acc.: 96.88%] [G loss: 1.279674]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "8 [D loss: 0.190454, acc.: 100.00%] [G loss: 1.394960]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "9 [D loss: 0.150492, acc.: 100.00%] [G loss: 1.577927]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "10 [D loss: 0.135855, acc.: 100.00%] [G loss: 1.680320]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "11 [D loss: 0.116460, acc.: 100.00%] [G loss: 1.794322]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "12 [D loss: 0.085819, acc.: 100.00%] [G loss: 1.892738]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "13 [D loss: 0.096881, acc.: 100.00%] [G loss: 2.067858]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "14 [D loss: 0.111254, acc.: 100.00%] [G loss: 2.101080]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "15 [D loss: 0.101823, acc.: 100.00%] [G loss: 2.255407]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "16 [D loss: 0.078400, acc.: 100.00%] [G loss: 2.530953]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "17 [D loss: 0.053620, acc.: 100.00%] [G loss: 2.471522]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "18 [D loss: 0.062846, acc.: 100.00%] [G loss: 2.541199]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "19 [D loss: 0.049899, acc.: 100.00%] [G loss: 2.595039]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "20 [D loss: 0.056073, acc.: 100.00%] [G loss: 2.622126]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "21 [D loss: 0.048640, acc.: 100.00%] [G loss: 2.813739]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "22 [D loss: 0.043207, acc.: 100.00%] [G loss: 3.016780]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "23 [D loss: 0.040577, acc.: 100.00%] [G loss: 2.895563]\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "24 [D loss: 0.034108, acc.: 100.00%] [G loss: 2.997935]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "25 [D loss: 0.051172, acc.: 100.00%] [G loss: 2.996811]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "26 [D loss: 0.032772, acc.: 100.00%] [G loss: 3.002266]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "27 [D loss: 0.039269, acc.: 100.00%] [G loss: 3.055892]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "28 [D loss: 0.029747, acc.: 100.00%] [G loss: 3.208113]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "29 [D loss: 0.033105, acc.: 100.00%] [G loss: 3.148456]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "30 [D loss: 0.034273, acc.: 100.00%] [G loss: 3.346939]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "31 [D loss: 0.027100, acc.: 100.00%] [G loss: 3.254788]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "32 [D loss: 0.023905, acc.: 100.00%] [G loss: 3.265329]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "33 [D loss: 0.020646, acc.: 100.00%] [G loss: 3.499038]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "34 [D loss: 0.023623, acc.: 100.00%] [G loss: 3.313486]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "35 [D loss: 0.026114, acc.: 100.00%] [G loss: 3.283575]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "36 [D loss: 0.027644, acc.: 100.00%] [G loss: 3.396026]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "37 [D loss: 0.022030, acc.: 100.00%] [G loss: 3.404449]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "38 [D loss: 0.012792, acc.: 100.00%] [G loss: 3.471356]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "39 [D loss: 0.021271, acc.: 100.00%] [G loss: 3.366067]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "40 [D loss: 0.018795, acc.: 100.00%] [G loss: 3.358939]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "41 [D loss: 0.015153, acc.: 100.00%] [G loss: 3.643320]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "42 [D loss: 0.015669, acc.: 100.00%] [G loss: 3.530104]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "43 [D loss: 0.019710, acc.: 100.00%] [G loss: 3.645551]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "44 [D loss: 0.018522, acc.: 100.00%] [G loss: 3.501148]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "45 [D loss: 0.023862, acc.: 100.00%] [G loss: 3.523195]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "46 [D loss: 0.019295, acc.: 100.00%] [G loss: 3.566474]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "47 [D loss: 0.024692, acc.: 100.00%] [G loss: 3.634534]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "48 [D loss: 0.023281, acc.: 100.00%] [G loss: 3.776428]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "49 [D loss: 0.011728, acc.: 100.00%] [G loss: 3.536652]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "50 [D loss: 0.020260, acc.: 100.00%] [G loss: 3.710264]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "51 [D loss: 0.016284, acc.: 100.00%] [G loss: 3.872624]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "52 [D loss: 0.015575, acc.: 100.00%] [G loss: 3.870088]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "53 [D loss: 0.017803, acc.: 100.00%] [G loss: 3.781375]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "54 [D loss: 0.022236, acc.: 100.00%] [G loss: 3.676677]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "55 [D loss: 0.013258, acc.: 100.00%] [G loss: 3.753074]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "56 [D loss: 0.014505, acc.: 100.00%] [G loss: 3.636397]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "57 [D loss: 0.017107, acc.: 100.00%] [G loss: 3.962913]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "58 [D loss: 0.018130, acc.: 100.00%] [G loss: 3.842229]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "59 [D loss: 0.014499, acc.: 100.00%] [G loss: 3.927316]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "60 [D loss: 0.024390, acc.: 100.00%] [G loss: 4.001385]\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "61 [D loss: 0.009758, acc.: 100.00%] [G loss: 3.986498]\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "62 [D loss: 0.020777, acc.: 100.00%] [G loss: 3.920799]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "63 [D loss: 0.016505, acc.: 100.00%] [G loss: 4.014166]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "64 [D loss: 0.011558, acc.: 100.00%] [G loss: 3.971013]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "65 [D loss: 0.018745, acc.: 100.00%] [G loss: 4.007451]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "66 [D loss: 0.017855, acc.: 100.00%] [G loss: 4.222001]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "67 [D loss: 0.013245, acc.: 100.00%] [G loss: 4.162988]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "68 [D loss: 0.016768, acc.: 100.00%] [G loss: 4.213487]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "69 [D loss: 0.012027, acc.: 100.00%] [G loss: 4.171682]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "70 [D loss: 0.009816, acc.: 100.00%] [G loss: 4.004907]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "71 [D loss: 0.013012, acc.: 100.00%] [G loss: 4.031589]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "72 [D loss: 0.007794, acc.: 100.00%] [G loss: 3.994110]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "73 [D loss: 0.021885, acc.: 100.00%] [G loss: 4.023694]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "74 [D loss: 0.014340, acc.: 100.00%] [G loss: 4.303278]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "75 [D loss: 0.012679, acc.: 100.00%] [G loss: 4.302917]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "76 [D loss: 0.011309, acc.: 100.00%] [G loss: 4.220980]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "77 [D loss: 0.014148, acc.: 100.00%] [G loss: 4.278215]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "78 [D loss: 0.030623, acc.: 100.00%] [G loss: 4.217049]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "79 [D loss: 0.013089, acc.: 100.00%] [G loss: 4.110273]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "80 [D loss: 0.012703, acc.: 100.00%] [G loss: 4.377208]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "81 [D loss: 0.008138, acc.: 100.00%] [G loss: 4.192430]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "82 [D loss: 0.017583, acc.: 100.00%] [G loss: 4.268077]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "83 [D loss: 0.008822, acc.: 100.00%] [G loss: 4.376000]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "84 [D loss: 0.015497, acc.: 100.00%] [G loss: 4.217768]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "85 [D loss: 0.007705, acc.: 100.00%] [G loss: 4.163573]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "86 [D loss: 0.016460, acc.: 100.00%] [G loss: 4.312226]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "87 [D loss: 0.019326, acc.: 100.00%] [G loss: 4.370523]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "88 [D loss: 0.016396, acc.: 100.00%] [G loss: 4.222598]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "89 [D loss: 0.015002, acc.: 100.00%] [G loss: 4.336797]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "90 [D loss: 0.020894, acc.: 100.00%] [G loss: 4.375748]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "91 [D loss: 0.016730, acc.: 100.00%] [G loss: 4.497424]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "92 [D loss: 0.010014, acc.: 100.00%] [G loss: 4.457707]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "93 [D loss: 0.012297, acc.: 100.00%] [G loss: 4.510608]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "94 [D loss: 0.019552, acc.: 100.00%] [G loss: 4.603346]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "95 [D loss: 0.010381, acc.: 100.00%] [G loss: 4.510813]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "96 [D loss: 0.005662, acc.: 100.00%] [G loss: 4.455964]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "97 [D loss: 0.010694, acc.: 100.00%] [G loss: 4.377614]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "98 [D loss: 0.014780, acc.: 100.00%] [G loss: 4.371397]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "99 [D loss: 0.017776, acc.: 100.00%] [G loss: 4.651043]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Yy9G3gEjVKXu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}